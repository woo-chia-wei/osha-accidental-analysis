{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import string\n",
    "import math\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag.stanford import StanfordPOSTagger, StanfordNERTagger\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import groupby\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_file(filename):\n",
    "    return os.path.join(os.getcwd(), 'output_data', filename)\n",
    "\n",
    "def import_data():\n",
    "    return pd.read_csv(get_output_file('01_data_extraction_final.csv'), index_col=0)\n",
    "\n",
    "def import_ner_data():\n",
    "    return pd.read_csv(get_output_file('02_data_preprocessing_ner.csv'), index_col=0)\n",
    "\n",
    "def import_dictionary_data():\n",
    "    return pd.read_csv(get_output_file('02_data_preprocessing_dictionary.csv'), index_col=0)\n",
    "\n",
    "def export_ner_data(df):\n",
    "    df.to_csv(get_output_file('02_data_preprocessing_ner.csv'))\n",
    "    \n",
    "def export_dictionary_data(df):\n",
    "    df.to_csv(get_output_file('02_data_preprocessing_dictionary.csv'))\n",
    "\n",
    "def export_combined_data(df):\n",
    "    df.to_csv(get_output_file('02_data_preprocessing_final.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing using Name Entity Recognition (NER)\n",
    "<span style=\"color:red\"><b>Important</b>: The NER process takes long processing time (few hours), this is just a one time call and save to a local file, not required for every run.</span>    \n",
    "\n",
    "Use standford NER tagger to extract following information:\n",
    "* Organization\n",
    "* Location\n",
    "* Date\n",
    "* Time\n",
    "\n",
    "Input file: <span style=\"color:blue; font-weight:bold\">01_data_extraction.csv</span>  \n",
    "Output file: <span style=\"color:blue; font-weight:bold\">02_data_preprocessing_ner.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Setup environment\n",
    "############################################\n",
    "java_path = 'C:\\\\Program Files\\\\Java\\\\jre1.8.0_121\\\\bin\\\\java.exe'\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "############################################\n",
    "# Define taggers\n",
    "############################################\n",
    "ner7_model_path = os.getcwd() + \"\\\\tools\\\\stanford-ner-2017-06-09\\\\english.muc.7class.distsim.crf.ser.gz\"\n",
    "ner_jar_path = os.getcwd() + \"\\\\tools\\\\stanford-ner-2017-06-09\\\\stanford-ner.jar\"\n",
    "st_ner7 = StanfordNERTagger(ner7_model_path, ner_jar_path)\n",
    "\n",
    "############################################\n",
    "# Import data\n",
    "############################################\n",
    "df = import_data()\n",
    "\n",
    "#############################################################################\n",
    "# # Loop through all rows and extract possible name entities from description\n",
    "#############################################################################\n",
    "count = 1\n",
    "total = len(df.index)\n",
    "date_list = []\n",
    "organization_list = []\n",
    "time_list = []\n",
    "location_list = []\n",
    "\n",
    "def list_name_entities(tagging_result):\n",
    "    \n",
    "    entities = {'DATE': set(), \n",
    "                'ORGANIZATION': set(), \n",
    "                'LOCATION': set(), \n",
    "                'TIME': set()}\n",
    "    \n",
    "    for tag, chunk in groupby(tagging_result, lambda x:x[1]):\n",
    "        if tag in entities.keys():\n",
    "            entity = ' '.join(w.strip() for w, t in chunk)\n",
    "            entities[tag].add(entity)\n",
    "            \n",
    "    for key, value in entities.items():\n",
    "        entities[key] = ', '.join(value)\n",
    "        \n",
    "    return entities\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    sent = row['description']\n",
    "    sent_ner7 = st_ner7.tag(word_tokenize(sent))\n",
    "    entities = list_name_entities(sent_ner7)\n",
    "    \n",
    "    date_list.append(entities['DATE'])\n",
    "    organization_list.append(entities['ORGANIZATION'])\n",
    "    time_list.append(entities['TIME'])\n",
    "    location_list.append(entities['LOCATION'])\n",
    "    \n",
    "    print(f\"Processing row {count} out of {total} with index {index}.\")\n",
    "    count = count + 1\n",
    "\n",
    "############################################\n",
    "# Add new colmumns into original dataframe\n",
    "############################################\n",
    "df['date'] = date_list\n",
    "df['organization'] = organization_list\n",
    "df['time'] = time_list\n",
    "df['location'] = location_list\n",
    "\n",
    "############################################\n",
    "# Export data\n",
    "############################################\n",
    "export_ner_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data preprocessing using dictionary\n",
    "Extract following information using dictionary matching\n",
    "* Occupation\n",
    "* Injured body parts\n",
    "* Is fatal?\n",
    "* Activity\n",
    "\n",
    "Input file: <span style=\"color:blue; font-weight:bold\">01_data_extraction.csv</span>  \n",
    "Output file: <span style=\"color:blue; font-weight:bold\">02_data_preprocessing_dictionary.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Import data\n",
    "################################\n",
    "df = import_data()\n",
    "\n",
    "################################\n",
    "# Create is_fatal column\n",
    "################################\n",
    "def detect_fatality(case_title):\n",
    "    \n",
    "    def generate_fatality_keywords():\n",
    "        fatality_list = ['death', 'killed', 'dead', 'fatal', 'fatally', 'dies', 'died']\n",
    "        stopword_fatality = ['fall', 'going', 'passing', 'expiration', 'loss', 'exit', 'remove', 'off', 'waste']\n",
    "        final_list = []\n",
    "        final_list = final_list + fatality_list\n",
    "        for fatal_kw in fatality_list:\n",
    "\n",
    "            dead_keywords = wn.synsets(fatal_kw)\n",
    "            dead = wn.synsets(fatal_kw)[0]\n",
    "            keywords = list(set([w for s in dead.closure(lambda s: s.hyponyms()) for w in s.lemma_names()]))\n",
    "            for kw in keywords:\n",
    "                if kw not in final_list and kw not in stopword_fatality:\n",
    "                    final_list.append(kw.replace('_', ' ').lower())\n",
    "        return final_list\n",
    "    \n",
    "    fatality_keyword_list = generate_fatality_keywords()\n",
    "    case_tokens = word_tokenize(str(case_title).lower())\n",
    "    is_fatal = False\n",
    "    \n",
    "    for case_t in case_tokens:\n",
    "        if case_t.strip() in fatality_keyword_list:\n",
    "            is_fatal = True\n",
    "    return is_fatal\n",
    "\n",
    "df['is_fatal'] = df['title'].apply(detect_fatality)\n",
    "\n",
    "################################\n",
    "# Create activity column\n",
    "################################\n",
    "df['activity'] = df['title']\n",
    "\n",
    "################################\n",
    "# Create body_parts column\n",
    "################################\n",
    "stop = stopwords.words('english')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "dict_body_parts = ['ankle', 'arch', 'arm', 'armpit', 'beard', 'breast', 'calf', 'cheek', 'chest', 'chin', 'earlobe', \n",
    "                   'elbow', 'eyebrow', 'eyelash', 'eyelid', 'face', 'finger', 'forearm', 'forehead', 'gum', 'heel', \n",
    "                   'hip', 'jaw', 'knee', 'knuckle', 'leg', 'lip', 'mouth', 'head']\n",
    "\n",
    "def detect_body_parts(keywords):\n",
    "    tokens = word_tokenize(keywords)\n",
    "    tokens_nop = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens_lower = [t.lower() for t in tokens_nop]\n",
    "    tokens_nostop = [t for t in tokens_lower if t not in stop]\n",
    "    tokens_lem = [wnl.lemmatize(t) for t in tokens_nostop]\n",
    "    body_parts = [t for t in set(tokens_lem) if t in dict_body_parts]\n",
    "    return ', '.join(body_parts)\n",
    "\n",
    "df['body_parts'] = (df['title'] + ' ' + df['description'] + ' ' + df['keywords']).apply(detect_body_parts)\n",
    "\n",
    "################################\n",
    "# Create occupation column\n",
    "################################\n",
    "\n",
    "\n",
    "################################\n",
    "# Export data\n",
    "################################\n",
    "export_dictionary_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combine all features\n",
    "Combine columns from separated files and export to final csv. Additional handling:\n",
    "* Date column will pick the first date in array\n",
    "* Not picking Orgnisation, Person, Location as too many missing values\n",
    "\n",
    "Input files: <span style=\"color:blue; font-weight:bold\">02_data_preprocessing_ner.csv, 02_data_preprocessing_dictionary.csv</span>  \n",
    "Output file: <span style=\"color:blue; font-weight:bold\">02_data_preprocessing.csv</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acitivty</th>\n",
       "      <th>date</th>\n",
       "      <th>body_parts</th>\n",
       "      <th>is_fatal</th>\n",
       "      <th>occupation</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202561825</th>\n",
       "      <td>Employee Falls From Flatbed Trailer And Later...</td>\n",
       "      <td>2013-08-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200361855</th>\n",
       "      <td>Two Workers Are Struck By Motor Vehicle And O...</td>\n",
       "      <td>2013-08-27 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200361863</th>\n",
       "      <td>Employee Is Struck By Bales Of Wire And Killed</td>\n",
       "      <td>2013-08-26 00:00:00</td>\n",
       "      <td>face, leg, head</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201079324</th>\n",
       "      <td>Employee Is Splashed With Hot Water And Is Bu...</td>\n",
       "      <td>2013-07-14 00:00:00</td>\n",
       "      <td>leg</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202658258</th>\n",
       "      <td>Employee Suffers Burns While Moving Soup</td>\n",
       "      <td>2013-06-30 00:00:00</td>\n",
       "      <td>arm, chest</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202685947</th>\n",
       "      <td>Employee Injures Self With Knife</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202673471</th>\n",
       "      <td>Foreman Is Fatally Crushed When Forklift Tips...</td>\n",
       "      <td>2013-05-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202369575</th>\n",
       "      <td>Employee Fractures Abdomen When Run Over By T...</td>\n",
       "      <td>2013-04-23 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202509832</th>\n",
       "      <td>Employee Suffers Abdominal Fracture In Fall F...</td>\n",
       "      <td>2013-04-09 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201129681</th>\n",
       "      <td>Carpenter Injured In Abdomen When Saw Kicks B...</td>\n",
       "      <td>2013-04-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    acitivty  \\\n",
       "case_id                                                        \n",
       "202561825   Employee Falls From Flatbed Trailer And Later...   \n",
       "200361855   Two Workers Are Struck By Motor Vehicle And O...   \n",
       "200361863    Employee Is Struck By Bales Of Wire And Killed    \n",
       "201079324   Employee Is Splashed With Hot Water And Is Bu...   \n",
       "202658258          Employee Suffers Burns While Moving Soup    \n",
       "202685947                  Employee Injures Self With Knife    \n",
       "202673471   Foreman Is Fatally Crushed When Forklift Tips...   \n",
       "202369575   Employee Fractures Abdomen When Run Over By T...   \n",
       "202509832   Employee Suffers Abdominal Fracture In Fall F...   \n",
       "201129681   Carpenter Injured In Abdomen When Saw Kicks B...   \n",
       "\n",
       "                          date       body_parts  is_fatal occupation topics  \n",
       "case_id                                                                      \n",
       "202561825  2013-08-30 00:00:00              NaN      True       None   None  \n",
       "200361855  2013-08-27 00:00:00              NaN      True       None   None  \n",
       "200361863  2013-08-26 00:00:00  face, leg, head      True       None   None  \n",
       "201079324  2013-07-14 00:00:00              leg     False       None   None  \n",
       "202658258  2013-06-30 00:00:00       arm, chest     False       None   None  \n",
       "202685947                 None              NaN     False       None   None  \n",
       "202673471  2013-05-13 00:00:00              NaN      True       None   None  \n",
       "202369575  2013-04-23 00:00:00              NaN     False       None   None  \n",
       "202509832  2013-04-09 00:00:00              NaN     False       None   None  \n",
       "201129681  2013-04-01 00:00:00              NaN     False       None   None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "# Import data\n",
    "################################\n",
    "df_ner = import_ner_data()\n",
    "df_dict = import_dictionary_data()\n",
    "\n",
    "################################\n",
    "# Combine data\n",
    "################################\n",
    "df = pd.DataFrame()\n",
    "df['acitivty'] = df_dict['activity']\n",
    "df['date'] = df_ner['date']\n",
    "df['body_parts'] = df_dict['body_parts']\n",
    "df['is_fatal'] = df_dict['is_fatal']\n",
    "df['occupation'] = None\n",
    "df['topics'] = None\n",
    "\n",
    "################################\n",
    "# Transformation\n",
    "################################\n",
    "\n",
    "def parse_date(dates):\n",
    "    dates = str(dates)\n",
    "    dates = [d.strip() for d in dates.split(',')]\n",
    "    for d in dates:\n",
    "        date = None\n",
    "        try:\n",
    "            date = parse(d)\n",
    "            return date\n",
    "        except ValueError:\n",
    "            continue       \n",
    "    return None\n",
    "\n",
    "df['date'] = df['date'].apply(parse_date)\n",
    "\n",
    "################################\n",
    "# Export data\n",
    "################################\n",
    "export_combined_data(df)\n",
    "\n",
    "################################\n",
    "# Inspect data\n",
    "################################\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acitivty</th>\n",
       "      <th>date</th>\n",
       "      <th>body_parts</th>\n",
       "      <th>is_fatal</th>\n",
       "      <th>occupation</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15963</td>\n",
       "      <td>12880</td>\n",
       "      <td>8069</td>\n",
       "      <td>15963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14393</td>\n",
       "      <td>4816</td>\n",
       "      <td>388</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Electric Shock</td>\n",
       "      <td>2011-06-22 00:00:00</td>\n",
       "      <td>finger</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>539</td>\n",
       "      <td>17</td>\n",
       "      <td>1569</td>\n",
       "      <td>10433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acitivty                 date body_parts is_fatal  occupation  \\\n",
       "count              15963                12880       8069    15963         0.0   \n",
       "unique             14393                 4816        388        2         0.0   \n",
       "top      Electric Shock   2011-06-22 00:00:00     finger    False         NaN   \n",
       "freq                 539                   17       1569    10433         NaN   \n",
       "\n",
       "        topics  \n",
       "count      0.0  \n",
       "unique     0.0  \n",
       "top        NaN  \n",
       "freq       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
